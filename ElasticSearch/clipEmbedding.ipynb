{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>caption</th>\n",
       "      <th>imgPath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Foreign-born population in the United States, ...</td>\n",
       "      <td>The foreign-born population residing in the U....</td>\n",
       "      <td>../dataset/pew_dataset/pew_imgs/1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>English proficiency among U.S. immigrants, 198...</td>\n",
       "      <td>Since 1980, the share of immigrants who are pr...</td>\n",
       "      <td>../dataset/pew_dataset/pew_imgs/2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Languages spoken among U.S. immigrants, 2018</td>\n",
       "      <td>Among the nation’s immigrants, Spanish is by f...</td>\n",
       "      <td>../dataset/pew_dataset/pew_imgs/3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hispanic population in the U.S., 2000-2017</td>\n",
       "      <td>There were nearly 60 million Latinos in the Un...</td>\n",
       "      <td>../dataset/pew_dataset/pew_imgs/4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Weekly broadcast audience for top 20 NPR-affil...</td>\n",
       "      <td>The top 20 NPR-affiliated public radio station...</td>\n",
       "      <td>../dataset/pew_dataset/pew_imgs/5.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  Foreign-born population in the United States, ...   \n",
       "1   2  English proficiency among U.S. immigrants, 198...   \n",
       "2   3       Languages spoken among U.S. immigrants, 2018   \n",
       "3   4         Hispanic population in the U.S., 2000-2017   \n",
       "4   5  Weekly broadcast audience for top 20 NPR-affil...   \n",
       "\n",
       "                                             caption  \\\n",
       "0  The foreign-born population residing in the U....   \n",
       "1  Since 1980, the share of immigrants who are pr...   \n",
       "2  Among the nation’s immigrants, Spanish is by f...   \n",
       "3  There were nearly 60 million Latinos in the Un...   \n",
       "4  The top 20 NPR-affiliated public radio station...   \n",
       "\n",
       "                                 imgPath  \n",
       "0  ../dataset/pew_dataset/pew_imgs/1.png  \n",
       "1  ../dataset/pew_dataset/pew_imgs/2.png  \n",
       "2  ../dataset/pew_dataset/pew_imgs/3.png  \n",
       "3  ../dataset/pew_dataset/pew_imgs/4.png  \n",
       "4  ../dataset/pew_dataset/pew_imgs/5.png  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load your DataFrame\n",
    "pew = pd.read_csv('../dataset/pew_dataset/metadata.csv')\n",
    "pew['imgPath'] = pew['imgPath'].str.replace('imgs', '../dataset/pew_dataset/pew_imgs')\n",
    "statista = pd.read_csv('../dataset/statista_dataset/metadata.csv')\n",
    "statista['imgPath'] = statista['imgPath'].str.replace('out/two_col/imgs', '../dataset/statista_dataset/statista_imgs')\n",
    "columns = ['title','caption','imgPath']\n",
    "\n",
    "# Filtering the DataFrame to include only the specified columns\n",
    "pew_df = pew[columns]\n",
    "statista_df = statista[columns]\n",
    "combined_df = pd.concat([pew_df, statista_df], ignore_index=True)\n",
    "\n",
    "# Add a new column 'ID' to the DataFrame at the first position\n",
    "combined_df.insert(0, 'id', combined_df.reset_index().index + 1)\n",
    "\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize CLIP model and processor\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(images, texts):\n",
    "    inputs = processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        image_embeddings = outputs.image_embeds  # Access image embeddings\n",
    "        text_embeddings = outputs.text_embeds    # Access text embeddings\n",
    "        return image_embeddings, text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image paths from DataFrame and take only the first 10\n",
    "image_paths = combined_df['imgPath'].tolist()[:10]\n",
    "\n",
    "# Load images\n",
    "images = [Image.open(path) for path in image_paths]\n",
    "\n",
    "# Specific text prompt for embedding generation, repeated for each image\n",
    "specific_text_prompt = [\"Provide a statistical summary and analysis of the chart\"] * len(images)\n",
    "\n",
    "# Generate embeddings for images and text\n",
    "image_embeddings, _ = generate_embeddings(images, specific_text_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# Create a blank white image, size 224x224 (common input size for image models like CLIP)\n",
    "image_size = (224, 224)\n",
    "color = (255, 255, 255)  # White background, RGB format\n",
    "\n",
    "# Create the image with the specified color and size\n",
    "dummy_image = Image.new(\"RGB\", image_size, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar image is: ../dataset/pew_dataset/pew_imgs/3.png\n"
     ]
    }
   ],
   "source": [
    "# Example text query with a dummy image\n",
    "text_query = [\"hispanic people\"]\n",
    "\n",
    "# Generate embedding for the text query with a placeholder image which is a dummy image\n",
    "_, query_embedding = generate_embeddings(dummy_image, text_query)\n",
    "\n",
    "# Normalize embeddings\n",
    "image_embeddings = image_embeddings / torch.norm(image_embeddings, dim=1, keepdim=True)\n",
    "query_embedding = query_embedding / torch.norm(query_embedding, dim=1, keepdim=True)\n",
    "\n",
    "# Calculate cosine similarities between the query embedding and all image embeddings\n",
    "similarities = cosine_similarity(query_embedding.cpu().numpy(), image_embeddings.cpu().numpy())  # Use .cpu() if on CUDA\n",
    "\n",
    "# Get the index of the highest similarity score\n",
    "most_similar_idx = np.argmax(similarities)\n",
    "\n",
    "# Retrieve the most similar image\n",
    "most_similar_image_path = image_paths[most_similar_idx]\n",
    "print(\"Most similar image is:\", most_similar_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 most similar images are:\n",
      "1: ../dataset/pew_dataset/pew_imgs/3.png\n",
      "2: ../dataset/pew_dataset/pew_imgs/2.png\n",
      "3: ../dataset/pew_dataset/pew_imgs/1.png\n"
     ]
    }
   ],
   "source": [
    "# Get indices of the top 3 highest similarity scores\n",
    "top_indices = np.argsort(similarities[0])[::-1][:3]  # Reverse sort and take top 3\n",
    "\n",
    "# Retrieve the paths of the most similar images\n",
    "top_images_paths = [image_paths[idx] for idx in top_indices]\n",
    "\n",
    "# Print the top 3 most similar images\n",
    "print(\"Top 3 most similar images are:\")\n",
    "for i, path in enumerate(top_images_paths, start=1):\n",
    "    print(f\"{i}: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sraEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
