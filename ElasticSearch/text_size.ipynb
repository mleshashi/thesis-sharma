{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29354, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataProcessor import process_metadata, pew_metadata_path, statista_metadata_path\n",
    "#  get the combined dataframe\n",
    "combined_df = process_metadata(pew_metadata_path, statista_metadata_path)\n",
    "combined_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (141 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>Confidence in public health organizations likely t...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>696</td>\n",
       "      <td>How Mixed-Race, Mestizo, 'uulatto' Hispanics Repor...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>917</td>\n",
       "      <td>Write- Ins for \"Some Other Race\" Among Hispanics i...</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>670</td>\n",
       "      <td>A Snapshot of What Americans Know About Science % ...</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>Roughly three-in-ten who say social media have a n...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>800</td>\n",
       "      <td>The Web IQ\" of American Internet Users % of finter...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>Majority of parents say their child 11 or younger ...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>661</td>\n",
       "      <td>Foreign- Born Hispanics More Likely to Be Catholic...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>415</td>\n",
       "      <td>The largest number of single-mother households are...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>336</td>\n",
       "      <td>No Muslim-majority nation was among top five U.S. ...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>25% of Americans who say social media have a posit...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>509</td>\n",
       "      <td>Most Americans say scientists should have a major ...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                                  title  token_length\n",
       "60    61  Confidence in public health organizations likely t...           141\n",
       "695  696  How Mixed-Race, Mestizo, 'uulatto' Hispanics Repor...           141\n",
       "916  917  Write- Ins for \"Some Other Race\" Among Hispanics i...           134\n",
       "669  670  A Snapshot of What Americans Know About Science % ...           128\n",
       "62    63  Roughly three-in-ten who say social media have a n...           109\n",
       "799  800  The Web IQ\" of American Internet Users % of finter...            96\n",
       "93    94  Majority of parents say their child 11 or younger ...            89\n",
       "660  661  Foreign- Born Hispanics More Likely to Be Catholic...            84\n",
       "414  415  The largest number of single-mother households are...            82\n",
       "335  336  No Muslim-majority nation was among top five U.S. ...            82\n",
       "63    64  25% of Americans who say social media have a posit...            81\n",
       "508  509  Most Americans say scientists should have a major ...            80"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import CLIPTokenizer, CLIPModel\n",
    "\n",
    "# Load the CLIP model and tokenizer\n",
    "model_name = \"openai/clip-vit-large-patch14\"\n",
    "tokenizer = CLIPTokenizer.from_pretrained(model_name)\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to tokenize the title using CLIP and get token length\n",
    "def get_clip_token_length(text):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\")\n",
    "    return tokens.input_ids.size(1)\n",
    "\n",
    "# Function to truncate the title\n",
    "def truncate_title(title, max_length=50):\n",
    "    if len(title) > max_length:\n",
    "        return title[:max_length] + \"...\"\n",
    "    return title\n",
    "\n",
    "# Apply the function to each title\n",
    "combined_df['token_length'] = combined_df['title'].apply(get_clip_token_length)\n",
    "\n",
    "# Select only the required columns\n",
    "combined_df = combined_df[['id', 'title', 'token_length']]\n",
    "\n",
    "combined_df = combined_df[combined_df['token_length'] > 77]\n",
    "\n",
    "# sort it with token length\n",
    "combined_df = combined_df.sort_values(by='token_length', ascending=False)\n",
    "\n",
    "# Truncate the title for display purposes\n",
    "combined_df['title'] = combined_df['title'].apply(truncate_title)\n",
    "\n",
    "combined_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>combined_token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11346</th>\n",
       "      <td>11347</td>\n",
       "      <td>\\r\\n                        Population of Poland fro...</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>7488</td>\n",
       "      <td>\\r\\n                        Population of Greece fro...</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8186</th>\n",
       "      <td>8187</td>\n",
       "      <td>\\r\\n                        Number of assassinations...</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>6541</td>\n",
       "      <td>\\r\\n                        Population of France fro...</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>4070</td>\n",
       "      <td>\\r\\n                        Reported number of slave...</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9525</th>\n",
       "      <td>9526</td>\n",
       "      <td>\\r\\n                        Number of electric passe...</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4395</th>\n",
       "      <td>4396</td>\n",
       "      <td>\\r\\n                        Crude oil imports to Can...</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1587</td>\n",
       "      <td>\\r\\n                        Total Nike retail stores...</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>1522</td>\n",
       "      <td>\\r\\n                        Number of coronavirus (C...</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6241</th>\n",
       "      <td>6242</td>\n",
       "      <td>\\r\\n                        Share of mobile banking ...</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1347 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                                    title  \\\n",
       "11346  11347  \\r\\n                        Population of Poland fro...   \n",
       "7487    7488  \\r\\n                        Population of Greece fro...   \n",
       "8186    8187  \\r\\n                        Number of assassinations...   \n",
       "6540    6541  \\r\\n                        Population of France fro...   \n",
       "4069    4070  \\r\\n                        Reported number of slave...   \n",
       "...      ...                                                      ...   \n",
       "9525    9526  \\r\\n                        Number of electric passe...   \n",
       "4395    4396  \\r\\n                        Crude oil imports to Can...   \n",
       "1586    1587  \\r\\n                        Total Nike retail stores...   \n",
       "1521    1522  \\r\\n                        Number of coronavirus (C...   \n",
       "6241    6242  \\r\\n                        Share of mobile banking ...   \n",
       "\n",
       "       combined_token_length  \n",
       "11346                   1217  \n",
       "7487                    1069  \n",
       "8186                    1046  \n",
       "6540                    1024  \n",
       "4069                     910  \n",
       "...                      ...  \n",
       "9525                     385  \n",
       "4395                     385  \n",
       "1586                     385  \n",
       "1521                     385  \n",
       "6241                     385  \n",
       "\n",
       "[1347 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from dataProcessor import process_metadata, pew_metadata_path, statista_metadata_path\n",
    "\n",
    "#  get the combined dataframe\n",
    "combined_df = process_metadata(pew_metadata_path, statista_metadata_path)\n",
    "combined_df.shape\n",
    "\n",
    "# Load the tokenizer and quantized model\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-mistral-7b-instruct')\n",
    "\n",
    "# Function to tokenize the caption and get token length\n",
    "def get_token_length(row):\n",
    "    # Combine the title and caption into one string\n",
    "    combined_text = row['title'] + \" \" + row['caption']\n",
    "    # Tokenize the text and count the number of input IDs, which represent tokens\n",
    "    tokens = tokenizer(combined_text, return_tensors=\"pt\")\n",
    "    return tokens['input_ids'].shape[1]  # Get the number of tokens\n",
    "\n",
    "# Apply the function to each row in your DataFrame to calculate token length for combined title and caption\n",
    "combined_df['combined_token_length'] = combined_df.apply(get_token_length, axis=1)\n",
    "\n",
    "# Select only the required columns to view the results\n",
    "combined_df = combined_df[['id', 'title', 'combined_token_length']]\n",
    "\n",
    "# Sort the DataFrame by token length in descending order\n",
    "combined_df = combined_df.sort_values(by='combined_token_length', ascending=False)\n",
    "\n",
    "# Display the DataFrame with combined token length for title and caption is more than 500\n",
    "combined_df = combined_df[combined_df['combined_token_length'] > 384]\n",
    "\n",
    "# Truncate the title for display purposes\n",
    "combined_df['title'] = combined_df['title'].apply(truncate_title)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mleshashi/thesis-sharma/sraEnv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, BitsAndBytesConfig\n",
    "\n",
    "# Quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# Function to load model\n",
    "def load_model(model_name, trust_remote_code=False):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=trust_remote_code)\n",
    "    model = AutoModel.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=trust_remote_code\n",
    "    )\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:17<00:00,  2.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load the second model with trust_remote_code=True\n",
    "model_name_2 = 'Alibaba-NLP/gte-Qwen2-7B-instruct'\n",
    "tokenizer_2, model_2 = load_model(model_name_2, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"model\": \"gpt-4o\",\n",
    " \"messages\": [\n",
    "  {\n",
    "   \"role\": \"user\",\n",
    "   \"content\": [\n",
    "    {\n",
    "     \"type\": \"text\",\n",
    "     \"text\": \"Please analyze the title, content, and the provided image data to provide statistical insights and answer the query.\\nTitle: What Is the Main Reason Gas\\nContent: About three-in-ten (31%) offer a variation on this theme \\u2013 greed, oil companies or speculation \\u2013 when asked what they think is the main reason gasoline prices have gone up recently, according to a Pew Research Center/Washington Post survey conducted April 28-May 1 among 1,006 adults.\\nRoughly two-in-ten (19%) cite the ongoing wars or unrest in Libya and elsewhere in the Middle East as the top reason for rising fuel prices. Another 14% attribute this to politics or national policies.\\nQuery: Are gas prices too high?\"\n",
    "    },\n",
    "    {\n",
    "     \"type\": \"image_url\",\n",
    "     \"image_url\": {\n",
    "      \"url\": \"data:image/jpeg;base64,iVBORw0KolssZgtTlIAAAAASUVORK5CYII=\"\n",
    "     }\n",
    "    }\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"role\": \"user\",\n",
    "   \"content\": [\n",
    "    {\n",
    "     \"type\": \"text\",\n",
    "     \"text\": \"Please analyze the title, content, and the provided image data to provide statistical insights and answer the query.\\nTitle: Average annual U.S. gasoline prices during times of crisis between 1956 and 2011 \\n                    \\n                            (in U.S. cents per gallon)\\nContent: This statistic shows average annual U.S. gasoline prices in selected times of crisis between 1956 and 2011. In 1956, the year of the Suez crisis, the average annual gasoline price in the U.S. stood at 249.9 U.S. cents per gallon.\\nQuery: Are gas prices too high?\"\n",
    "    },\n",
    "    {\n",
    "     \"type\": \"image_url\",\n",
    "     \"image_url\": {\n",
    "      \"url\": \"data:image/jpeg;base64,iVBORw0KGgWfahWENGywF4jEi1R3BbkX7xesAwAAAFgO+YXl/mr//t0am5u98LMe8bo2gg+XwDDG6P8P6vceKy2oWYQAAAAASUVORK5CYII=\"\n",
    "     }\n",
    "    }\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"max_tokens\": 300\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"model\": \"gpt-4o\",\n",
    " \"messages\": [\n",
    "  {\n",
    "   \"role\": \"user\",\n",
    "   \"content\": [\n",
    "    {\n",
    "     \"type\": \"text\",\n",
    "     \"text\": \"Please analyze the title, content, and the provided image data to provide statistical insights and answer the query.\\nTitle: What Is the Main Reason Gas\\nContent: About three-in-ten (31%) offer a variation on this theme \\u2013 greed, oil companies or speculation \\u2013 when asked what they think is the main reason gasoline prices have gone up recently, according to a Pew Research Center/Washington Post survey conducted April 28-May 1 among 1,006 adults.\\nRoughly two-in-ten (19%) cite the ongoing wars or unrest in Libya and elsewhere in the Middle East as the top reason for rising fuel prices. Another 14% attribute this to politics or national policies.\\nQuery: Are gas prices too high?\"\n",
    "    },\n",
    "    {\n",
    "     \"type\": \"image_url\",\n",
    "     \"image_url\": {\n",
    "      \"url\": \"data:image/jpeg;base64,iVBORw0KtMTu9WeHY+XJYBaQH8HbpPAKvoPgGsIuUAq0g5wCpSDrCKlAOsIuUAq0g5wCpSDrCqfl5uNpv94ziA11b1nNB9AlhFYQlYRcoBVpFygFU/HolssZgtTlIAAAAASUVORK5CYII=\"\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"type\": \"text\",\n",
    "     \"text\": \"Please analyze the title, content, and the provided image data to provide statistical insights and answer the query.\\nTitle: Average annual U.S. gasoline prices during times of crisis between 1956 and 2011 \\n                    \\n                            (in U.S. cents per gallon)\\nContent: This statistic shows average annual U.S. gasoline prices in selected times of crisis between 1956 and 2011. In 1956, the year of the Suez crisis, the average annual gasoline price in the U.S. stood at 249.9 U.S. cents per gallon.\\nQuery: Are gas prices too high?\"\n",
    "    },\n",
    "    {\n",
    "     \"type\": \"image_url\",\n",
    "     \"image_url\": {\n",
    "      \"url\": \"data:image/jpeg;base64,iVBORw0KVliUDUoutl/EI/G1c1iN53Sj48OOK+KCSilFEE3WfahWENGywF4jEi1R3BbkX7xesAwAAAFgO+YXl/mr//t0am5u98LMe8bo2gg+XwDDG6P8P6vceKy2oWYQAAAAASUVORK5CYII=\"\n",
    "     }\n",
    "    }\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"max_tokens\": 300\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sraEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
